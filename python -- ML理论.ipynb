{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Trading and Mechine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "监督学习：需要带有标签的样本，Features-->label 如分类，回归问题\n",
    "无监督学习：训练样本不含标签，如聚类问题，降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "模型选择，如果数据中包含特征和标签，希望学习特征和标签之间的对应关系，那么可以采用监督学习\n",
    "如果没有标签，希望探索特征自身的规律，那么可以采用非监督学习\n",
    "如果学习任务由一系列行动和对应的奖励组成，那么可以采用强化学习\n",
    "徐国需要预测的标签是分类变量，比如预测股票上涨还是下跌，那么可以采用分类的方法\n",
    "如果标签是连续的数值变量，比如预测股票具体涨多少，那么可以采用回归方法\n",
    "另外，样本和特征的个数，数据本身的特点，这些都决定了最终选择哪一种机器学习方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "训练集 Traning set\n",
    "验证集 Validation set 参数优化\n",
    "测试集 Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据获取（爬虫，数据库）--> 特征提取（经验和探索） --> 数据转换（缺失值，标准化，降维） --> 模型训练（适合的机器学习方法） --> 模型选择（交叉验证，模型评价指标） --> 模型预测（最优模型预测动态调整）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过拟合（训练集bias&测试集variance），泛化能力，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠拟合：highbias  过拟合：highvariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "监督学习算法介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归 linear regression\n",
    "连续问题\n",
    "y = (w0)x + (w1)b \n",
    "costfunction损失函数最小化/惩罚系数/回归系数\n",
    "找出costfunction是算法的关键\n",
    "|actual-predict|\n",
    "gradient descent 梯度下降\n",
    "解决过拟合的方法：正则化，在costfunction里面加入惩罚项penalty\n",
    "ridge岭回归：高次项惩罚系数加大，解决过拟合\n",
    "Lasso回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归 logistic regression\n",
    "分类问题\n",
    "梯度下降：gradient descent 损失函数是连续的（离散 --》 连续）加入惩罚项 penalty，不连续可能会导致局部最优\n",
    "decision boundary\n",
    "definition of cost function\n",
    "probability\n",
    "activation function激活函数（sigmoid function）\n",
    "极大似然估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持向量机SVM\n",
    "SVC：分类\n",
    "SVR：回归\n",
    "超平面，样本离决策边界最小值最大，线性分类器\n",
    "决定超平面位置的样本，就叫支持向量，让支持向量到超平面的距离最小值最大\n",
    "核函数kernel，把低维线性不可分的数据，投影到高维，找到超平面，线性可分（线性核，高斯核，多项式核）\n",
    "引入新特征，投影到高维空间，线性可分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树 decision tree\n",
    "decidion tree classify\n",
    "decision tree regression\n",
    "训练速度快\n",
    "可以处理非数值类的特征\n",
    "可以实现非线性分类\n",
    "叶子节点：\n",
    "根节点：\n",
    "根据一系列节点判断结果进行分类\n",
    "单棵决策树预测能力有限，将多个弱分类器组合成一个强分类器\n",
    "并行方法：Bootstrap-->Bagging方法-->抽样的每个样本都进行分类训练，得到一个弱分类器 random forest\n",
    "串行方法：adaboost（Adaptive Boosting），以原始数据为样本进行训练得到一个弱分类器，对于分类错误的样本提高其权重，在此训练得到第二个弱分类器，迭代如上过程，分类错误的样本越来越少得到一个强分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN算法（K-nearset neighbor）：如果两个样本的各个特征都非常接近，那么他们很可能属于同一类别\n",
    "K近邻，二分类问题最少要K=3，当K越小，分类样本bias越低，容易产生过拟合，反之，分类不够准确欠拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络和深度学习 neural network & deep learning\n",
    "复杂性，内部模型不可见\n",
    "input layer --> weight --> sigmoid(activate function) -- output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means\n",
    "K是分类簇的个数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
